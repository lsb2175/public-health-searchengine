import string
import nltk
from nltk.tokenize import TreebankWordTokenizer
from nltk.stem.porter import PorterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
from collections import Counter

# Sample public health job postings
docs = [
    "Epidemiologist: Responsible for analyzing public health data and developing disease prevention strategies.",
    "Health Communication Specialist: Develops educational materials and campaigns to promote public health initiatives.",
    "Biostatistician: Uses statistical methods to analyze health research data and inform policy decisions.",
    "Community Health Worker: Engages with local communities to improve health outcomes through outreach and education.",
    "Environmental Health Scientist: Investigates environmental factors affecting public health and develops safety regulations."
]

REMOVE_PUNCTUATION_TABLE = str.maketrans({x: None for x in string.punctuation})
TOKENIZER = TreebankWordTokenizer()
STEMMER = PorterStemmer()

def tokenize_and_stem(s):
    return [STEMMER.stem(t) for t in TOKENIZER.tokenize(s.translate(REMOVE_PUNCTUATION_TABLE))]

vectorizer = TfidfVectorizer(tokenizer=tokenize_and_stem, stop_words='english')
vectorizer.fit(docs)

doc_vectors = vectorizer.transform(docs)

class Scorer():
    def __init__(self, docs):
        self.docs = docs
        self.vectorizer = TfidfVectorizer(tokenizer=tokenize_and_stem, stop_words='english')
        self.doc_tfidf = self.vectorizer.fit_transform(docs)
        self.features = [self._feature_tfidf, self._feature_positive_feedback]
        self.feature_weights = [1.0, 2.0]
        self.feedback = {}

    def score(self, query):
        feature_vectors = [feature(query) for feature in self.features]
        feature_vectors_weighted = [feature * weight for feature, weight in zip(feature_vectors, self.feature_weights)]
        return np.sum(feature_vectors_weighted, axis=0)

    def learn_feedback(self, feedback_dict):
        self.feedback = feedback_dict

    def _feature_tfidf(self, query):
        query_vector = self.vectorizer.transform([query])
        similarity = cosine_similarity(query_vector, self.doc_tfidf)
        return similarity.ravel()

    def _feature_positive_feedback(self, query):
        if not self.feedback:
            return np.zeros(len(self.docs))
        feedback_queries = list(self.feedback.keys())
        similarity = cosine_similarity(self.vectorizer.transform([query]),
                                       self.vectorizer.transform(feedback_queries))
        nn_similarity = np.max(similarity)
        nn_idx = np.argmax(similarity)
        pos_feedback_doc_idx = [idx for idx, feedback_value in
                                self.feedback[feedback_queries[nn_idx]]
                                if feedback_value == 1.]
        feature_values = {
            doc_idx: nn_similarity * count / sum(Counter(pos_feedback_doc_idx).values())
            for doc_idx, count in Counter(pos_feedback_doc_idx).items()
        }
        return np.array([feature_values.get(doc_idx, 0.) for doc_idx, _ in enumerate(self.docs)])

scorer = Scorer(docs)
query = "public health communication outreach"
query_scores = scorer.score(query)
most_relevant_job = docs[query_scores.argmax()]

print(f"Best match for '{query}': {most_relevant_job}")
